<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="keywords" content="Yan Huang, 黄岩, CRIPAC, NLPR, CASIA, Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences, UESTC" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="style.css" type="text/css" />
<!-- <link rel="shortcut icon" href="fig/cripac.png"> -->
<title>Yan Huang's Homepage</title>
</head>
<body>
<div id="layout-content">

<script type="text/javascript">
<!--
// Toggle Display of BibTeX
function toggleBibtex(articleid) {
  var bib = document.getElementById(articleid);
  // Toggle 
    if(bib.style.display == "none") {
      bib.style.display = "";
    }
    else {
      bib.style.display = "none";
    }
}
-->
</script>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-40926388-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<table class="imgtable"><tr><td>
<img src="fig/yhuang.jpg" alt="alt text" width="400px" height="210px" /> &nbsp;</td>
<td align="left">

<div id="toptitle"> 
  <h1>
  <a href="https://yanrockhuang.github.io/">Yan Huang</a> &nbsp; 黄岩
  </h1>
</div>

<p>
Associate Professor, Ph.D.
<br />
<br />
<a href="https://scholar.google.com/citations?user=6nUJrQ0AAAAJ&hl=zh-CN">Google Scholar</a> <br />
Email: <a href="mailto:yhuang@nlpr.ia.ac.cn">yhuang at nlpr.ia.ac.cn</a><br />
Address: No.95 ZhongGuanCun East St, Beijing, China, 100190<br />
</p>
</td></tr></table>

  
  
<h2>News</h2>
<ul>
<li> <p>2020.06.19, We are organizing <a href="https://languageandvision.github.io/">CVPR 2020 Workshop on Language & Vision with Applications to Video Understanding</a> </p></li> 
<li> <p>2020.06.19, We are organizing <a href="https://mul-workshop.github.io/">CVPR 2020 Workshop on Multimodal Learning</a> </p></li> 
<li> <p>2019.11.02, We are organizing <a href="https://cromol.github.io/">ICCV 2019 Workshop on CroMoL: Cross-Modal Learning in Real World</a> </p></li> 
</ul>

<h2>
  Biography 
</h2>
<p>
Yan Huang received the BSc degree from University of Electronic Science and Technology of China (UESTC) in 2012, 
  and the PhD degree from University of Chinese Academy of Sciences (UCAS) in 2017. 
  Since July 2017, he has joined the National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA) as an associate professor. 
His research interests include computer vision and cross-modal data analysis. He has obtained awards such as the Presidential Special Award of CAS, Excellent Doctoral Thesis
of both CAS and CAAI, NVIDIA Pioneering Research Award, Baidu Fellowship, CVPR 2014 Workshop Best Paper Award, ICPR 2014 Best Student Paper Award,
and RACV 2016 Best Poster Award. 
</p>


<h2> Selected Journal Papers</h2> 
<ul>
<li><p>Jianhua Yang, <strong>Yan Huang</strong>, Kai Niu, Linjiang Huang, Zhanyu Ma, and Liang Wang, Actor and Action Modular Network for Text-based Video Segmentation, <i>IEEE Transactions on Image Processing (<strong>IEEE TIP</strong>)</i>, accepted, 2022. <a href="" target="_self">PDF</a> </p></li>
<li><p><strong>Yan Huang</strong>, Yuming Wang, and Liang Wang, Efficient Image and Sentence Matching, <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>)</i>, accepted, 2022. <a href="" target="_self">PDF</a> </p></li>
<li><p>Wenlong Cheng, Wei Tang, <strong>Yan Huang</strong>, Yiwen Luo, and Liang Wang, A Reconstruction-based Visual-Acoustic-Semantic Embedding Method for Speech-Image Retrieval, <i>IEEE Transactions on Multimedia (<strong>IEEE TMM</strong>)</i>, accepted, 2022. <a href="https://ieeexplore.ieee.org/document/9765364" target="_self">PDF</a> </p></li>
<li><p>Hongyuan Yu, Houwen Peng, <strong>Yan Huang</strong>, Hao Du, Jianlong Fu, Liang Wang, and Haibin Ling, Cyclic Differentiable Architecture Search, <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>)</i>, accepted, 2022. <a href="https://arxiv.org/pdf/2006.10724.pdf" target="_self">PDF</a> </p></li>
<li><p>Zerui Chen, <strong>Yan Huang</strong>, Hongyuan Yu, and Liang Wang, Learning a Robust Part-Aware Monocular 3D Human Pose Estimator via Neural Architecture Search, <i>International Journal of Computer Vision (<strong>IJCV</strong>)</i>, 130: 56–75, 2022. <a href="https://link.springer.com/article/10.1007/s11263-021-01525-0" target="_self">PDF</a> </p></li>  
<li><p><strong>Yan Huang</strong>, Jingdong Wang, and Liang Wang, Few-Shot Image and Sentence Matching via Aligned Cross-Modal Memory, <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>)</i>, 44(6): 2968-2983, 2022. <a href="https://ieeexplore.ieee.org/document/9328198" target="_self">PDF</a> </p></li>
<li><p>Yuchun Fang, Zhengye Xiao, Wei Zhang, <strong>Yan Huang</strong>, Liang Wang, Nozha Boujemaa, and Donald Geman, Attribute Prototype Learning for Interactive Face Retrieval, <i>IEEE Transactions on Information Forensics and Security (<strong>IEEE TIFS</strong>)</i>, 16: 2593-2607, 2021. <a href="https://ieeexplore.ieee.org/document/9354184" target="_self">PDF</a> </p></li>
<li><p>Chao Fan, Hongyuan Yu, <strong>Yan Huang</strong>, Caifeng Shan, Liang Wang, and Chenglong Li, SiamON: Siamese Occlusion-aware Network for Visual Tracking, <i>IEEE Transactions on Circuits and Systems for Video Technology (<strong>IEEE TCSVT</strong>)</i>, accepted, 2021. <a href="https://ieeexplore.ieee.org/document/9508452" target="_self">PDF</a> </p></li>
<li><p>Linjiang Huang, <strong>Yan Huang</strong>, Wanli Ouyang, and Liang Wang, Two-Branch Relational Prototypical Network for Weakly Supervised Temporal Action Localization, <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>)</i>, accepted, 2021. <a href="https://ieeexplore.ieee.org/document/9417653" target="_self">PDF</a> </p></li>
<li><p>Linjiang Huang, <strong>Yan Huang</strong>, Wanli Ouyang, and Liang Wang, Modeling Sub-Actions for Weakly Supervised Temporal Action Localization, <i>IEEE Transactions on Image Processing (<strong>IEEE TIP</strong>)</i>, 30: 5154-5167, 2021. <a href="https://ieeexplore.ieee.org/document/9430747" target="_self">PDF</a> </p></li>
<li><p>Aihua Zheng, Menglan Hu, Bo Jiang, <strong>Yan Huang</strong>, Yan Yan, and Bin Luo, Adversarial-Metric Learning for Audio-Visual Cross-Modal Matching, <i>IEEE Transactions on Multimedia (<strong>IEEE TMM</strong>)</i>, 24: 338-351, 2021. <a href="https://ieeexplore.ieee.org/document/9320535" target="_self">PDF</a> </p></li>

<li><p>Hongyuan Yu, <strong>Yan Huang</strong>, Lihong Pi, Chengquan Zhang, Xuan Li, and Liang Wang, End-to-end Video Text Detection with Online Tracking, <i>Pattern Recognition (<strong>PR</strong>)</i>, accepted, 2021. <a href="https://www.sciencedirect.com/science/article/abs/pii/S003132032030594X" target="_self">PDF</a> </p></li>
<li><p>Ke Han, <strong>Yan Huang</strong>, Chunfeng Song, Liang Wang, and Tieniu Tan, Adaptive Super-Resolution for Person Re-Identification with Low-Resolution Images, <i>Pattern Recognition (<strong>PR</strong>)</i>, accepted, 2021. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320320304854" target="_self">PDF</a> </p></li>
<li><p><strong>Yan Huang</strong>, Qi Wu, Wei Wang, and Liang Wang, Image and Sentence Matching via Semantic Concepts and Order Learning, <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>)</i>, 42(3): 636-650, 2020. <a href="https://ieeexplore.ieee.org/document/8550752" target="_self">PDF</a> </p></li>
<li><p>Kai Niu, <strong>Yan Huang</strong>, Wanli Ouyang, and Liang Wang, Improving Description-based Person Re-identification by Multi-granularity Image-text Alignments, <i>IEEE Transactions on Image Processing (<strong>IEEE TIP</strong>)</i>, 29: 5542-5556, 2020. <a href="https://ieeexplore.ieee.org/abstract/document/9058976" target="_self">PDF</a> </p></li>
<li><p>Weining Wang, <strong>Yan Huang</strong>, and Liang Wang, Long Video Question Answering: A Matching-guided Attention Model, <i>Pattern Recognition (<strong>PR</strong>)</i>, accepted, 2020. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320320300546" target="_self">PDF</a> </p></li>
<li><p>Kai Niu, <strong>Yan Huang</strong>, and Liang Wang, Re-ranking Image-text Matching by Adaptive Metric Fusion, <i>Pattern Recognition (<strong>PR</strong>)</i>, accepted, 2020. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320320301540" target="_self">PDF</a> </p></li>
  
  
<li><p>Chunfeng Song, Yongzhen Huang, <strong>Yan Huang</strong>, Ning Jia, and Liang Wang, GaitNet: An End-to-end Network for Gait Based Human Identification, <i>Pattern Recognition (<strong>PR</strong>)</i>, accepted, 2019. <a href="https://www.sciencedirect.com/science/article/pii/S0031320319302912" target="_self">PDF</a> </p></li>
<li><p>Linjiang Huang, <strong>Yan Huang</strong>, Wanli Ouyang, and Liang Wang, Part-Aligned Pose-Guided Recurrent Network for Action Recognition, <i>Pattern Recognition (<strong>PR</strong>)</i>, 96:165-176, 2019. <a href="https://www.sciencedirect.com/science/article/pii/S0031320319301098" target="_self">PDF</a> </p></li>
<!--<li><p>Yanyun Wang, Chunfeng Song, <strong>Yan Huang</strong>, and Liang Wang, Learning View Invariant Gait Features with Two-Stream GAN, <strong>Neurocomputing</strong>, accepted, 2019. <a href="https://www.sciencedirect.com/science/article/pii/S0925231219302395" target="_self">PDF</a> </p></li> -->
<!--<li><p>Qiang Cui, Shu Wu, <strong>Yan Huang</strong>, and Liang Wang, A Hierarchical Contextual Attention-based Network for Sequential Recommendation, <strong>Neurocomputing</strong>, accepted, 2019. <a href="https://www.sciencedirect.com/science/article/pii/S0925231219306642" target="_self">PDF</a> </p></li> -->

<li><p><strong>Yan Huang</strong>, Wei Wang, and Liang Wang, Video Super-resolution via Bidirectional Recurrent Convolutional Networks, <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>)</i>, 40(4), 1015-1028, 2018. <a href="https://ieeexplore.ieee.org/abstract/document/7919264" target="_self">PDF</a> </p></li>
<li><p><strong>Yan Huang</strong>, Wei Wang, Liang Wang, and Tieniu Tan, Conditional High-order Boltzmann Machines for Supervised Relation Learning, <i>IEEE Transactions on Image Processing (<strong>IEEE TIP</strong>)</i>, 26(9):4297-4310, 2017. <a href="https://ieeexplore.ieee.org/document/7913581" target="_self">PDF</a> </p></li>
<li><p><strong>Yan Huang</strong>, Wei Wang, and Liang Wang, Unconstrained Multimodal Multi-Label Learning, <i>IEEE Transactions on Multimedia (<strong>IEEE TMM</strong>)</i>, 17(11):1923-1935, 2015. <a href="https://ieeexplore.ieee.org/document/7239600" target="_self">PDF</a> </p></li>
</ul>
  
  
<h2>Selected Conference Papers</h2> 


<ul>
<li><p>Hongyuan Yu, Tian Li, Weichen Yu, Jianguo Li, <strong>Yan Huang</strong>, Liang Wang, and Alex Liu, Regularized Graph Structure Learning with Semantic Knowledge for Multi-variates Time-Series Forecasting, <i>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</i>, accepted, 2022. <a href="" target="_self">PDF</a> </p></li>
<li><p>Zhengxiong Luo, <strong>Yan Huang*</strong>, Shang Li, Liang Wang, and Tieniu Tan, Learning the Degradation Distribution for Blind Image Super-Resolution, <i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, accepted, 2022. <a href="https://arxiv.org/pdf/2203.04962.pdf" target="_self">PDF</a> </p></li>
<li><p>Ke Han, Chenyang Si, <strong>Yan Huang*</strong>, Liang Wang, and Tieniu Tan, Generalizable Person Re-Identification via Self-Supervised Batch Norm Test-Time Adaption, <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, accepted, 2022. <a href="https://www.aaai.org/AAAI22Papers/AAAI-7241.HanK.pdf" target="_self">PDF</a> </p></li>
<li><p>Keji He, <strong>Yan Huang</strong>, Qi Wu, Jianhua Yang, Dong An, Shuanglin Sima, and Liang Wang, Landmark-RxR: Solving Vision-and-Language Navigation with Fine-Grained Alignment Supervision, <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2021. <a href="https://proceedings.neurips.cc/paper/2021/file/0602940f23884f782058efac46f64b0f-Paper.pdf" target="_self">PDF</a> </p></li>
<li><p>Dong An, Yuankai Qi, <strong>Yan Huang*</strong>, Qi Wu, Liang Wang, and Tieniu Tan, Neighbor-view Enhanced Model for Vision and Language Navigation, <i>ACM Conference on Multimedia (<strong>MM</strong>)</i>, accepted, 2021. (<font color="#FF0000">Oral</font>) <a href="https://arxiv.org/pdf/2107.07201.pdf" target="_self">PDF</a> </p></li>
<li><p>Zhengxiong Luo, Zhicheng Wang, <strong>Yan Huang</strong>, Shang Li, Liang Wang, Tieniu Tan, and Erjin Zhou, Rethinking the Heatmap Regression for Bottom-Up Human Pose Estimation, <i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, pp. 13264-13273, 2021. <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Luo_Rethinking_the_Heatmap_Regression_for_Bottom-Up_Human_Pose_Estimation_CVPR_2021_paper.pdf" target="_self">PDF</a> </p></li>
  
<li><p>Zhengxiong Luo, <strong>Yan Huang*</strong>, Shang Li, Liang Wang, and Tieniu Tan, Unfolding the Alternating Optimization for Blind Super Resolution, <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2020. <a href="https://proceedings.neurips.cc//paper/2020/file/3d2d8ccb37df977cb6d9da15b76c3f3a-Paper.pdf" target="_self">PDF</a> </p></li>
<li><p>Kai Niu, <strong>Yan Huang</strong>, and Liang Wang, Textual Dependency Embedding for Person Search by Language, <i>ACM Conference on Multimedia (<strong>MM</strong>)</i>, pp. 4032–4040, 2020. <a href="https://dl.acm.org/doi/10.1145/3394171.3413895" target="_self">PDF</a> </p></li>
<li><p>Zerui Chen, <strong>Yan Huang</strong>, Hongyuan Yu, Bin Xue, Ke Han, Yiru Guo, and Liang Wang, Towards Part-aware Monocular 3D Human Pose Estimation: An Architecture Search Approach, <i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, accepted, 2020. (<font color="#FF0000">Spotlight</font>) <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123480715.pdf" target="_self">PDF</a> </p></li>
<li><p>Ke Han, <strong>Yan Huang</strong>, Zerui Chen, Liang Wang, Tieniu Tan, Prediction, Recovery and Identification: Adaptive Low-Resolution Person Re-Identification, <i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, accepted, 2020. <a href="https://yanrockhuang.github.io/" target="_self">PDF</a> </p></li>

  
<li><p>Linjiang Huang, <strong>Yan Huang</strong>, Wanli Ouyang, and Liang Wang, Relational Prototypical Network for Weakly Supervised Temporal Action Localization, <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, accepted, 2020. (<font color="#FF0000">Oral</font>) <a href="https://aaai.org/Papers/AAAI/2020GB/AAAI-HuangL.1235.pdf" target="_self">PDF</a> </p></li>
<li><p>Linjiang Huang, <strong>Yan Huang</strong>, Wanli Ouyang, and Liang Wang, Part-Level Graph Convolutional Network for Skeleton-Based Action Recognition, <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, accepted, 2020. (<font color="#FF0000">Oral</font>) <a href="https://www.aaai.org/Papers/AAAI/2020GB/AAAI-HuangL.1236.pdf" target="_self">PDF</a> </p></li>


<li><p><strong>Yan Huang</strong> and Liang Wang, ACMM: Aligned Cross-Modal Memory For Few-Shot Image and Sentence Matching, <i>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</i>, pp. 5774-5783, 2019. <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_ACMM_Aligned_Cross-Modal_Memory_for_Few-Shot_Image_and_Sentence_Matching_ICCV_2019_paper.pdf" target="_self">PDF</a> </p></li>
<li><p><strong>Yan Huang</strong>, Yang Long, and Liang Wang, Few-Shot Image and Sentence Matching via Gated Visual-Semantic Embedding, <i>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</i>, pp. 8489-8496, 2019. (<font color="#FF0000">Spotlight</font>) <a href="https://www.aaai.org/ojs/index.php/AAAI/article/download/4866/4739" target="_self">PDF</a> </p></li>
<li><p>Weining Wang, <strong>Yan Huang</strong>, and Liang Wang, Language-driven Temporal Activity Localization: A Semantic Matching Reinforcement Learning Model, <i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, pp. 334-343, 2019. (<font color="#FF0000">Oral</font>) <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Language-Driven_Temporal_Activity_Localization_A_Semantic_Matching_Reinforcement_Learning_Model_CVPR_2019_paper.pdf" target="_self">PDF</a> </p></li>
<li><p>Chunfeng Song, <strong>Yan Huang</strong>, Wanli Ouyang, and Liang Wang, Box-driven Class-wise Region Masking and Filling Rate Guided Loss for Weakly Supervised Semantic Segmentation, <i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, pp. 3136-3145, 2019. <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Song_Box-Driven_Class-Wise_Region_Masking_and_Filling_Rate_Guided_Loss_for_CVPR_2019_paper.pdf" target="_self">PDF</a> </p></li>
<li><p>Kai Niu, <strong>Yan Huang</strong>, and Liang Wang, Fusing Two Directions in Cross-domain Adaption for Real Life Person Search by Language, <i>IEEE International Conference on Computer Vision Workshop (<strong>ICCVW</strong>)</i>, 2019. (<font color="#FF0000">Oral</font>) <a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/WIDER/Niu_Fusing_Two_Directions_in_Cross-Domain_Adaption_for_Real_Life_Person_ICCVW_2019_paper.pdf" target="_self">PDF</a> </p></li>
<!--<li><p>Zerui Chen, <strong>Yan Huang</strong>, and Liang Wang, Learning Depth-aware Heatmaps for 3D Human Pose Estimation in the Wild, <strong>BMVC</strong>, 2019. <a href="https://bmvc2019.org/wp-content/uploads/papers/1217-paper.pdf" target="_self">PDF</a> </p></li>
<li>Wu Zheng, Lin Li, Zhaoxiang Zhang, <strong>Yan Huang</strong>, and Liang Wang, Relational Network for Skeleton-Based Action Recognition, <strong>ICME</strong>, 2019. (<font color="#FF0000">Oral</font>) <a href="https://ieeexplore_ieee.xilesou.top/abstract/document/8784961" target="_self">PDF</a> </p></li>
<li><p>Hongyuan Yu, <strong>Yan Huang</strong>, Lihong Pi, and Liang Wang, Recurrent Deconvolutional Generative Adversarial Networks with Application to Video Generation, <strong>PRCV</strong>, 2019. <a href="" target="_self">PDF</a> </p></li>
<li><p>Linjiang Huang, <strong>Yan Huang</strong>, Wanli Ouyang, and Liang Wang, Hierarchical Graph Convolutional Network For Skeleton-Based Action Recognition, <strong>ICIG</strong>, accepted, 2019. <a href="" target="_self">PDF</a> </p></li>
<li><p>Zerui Chen, <strong>Yan Huang</strong>, and Liang Wang, Augmented Visual-Semantic Embeddings for Image and Sentence Matching, <strong>ICIP</strong>, accepted, 2019. <a href="https://ieeexplore_ieee.xilesou.top/abstract/document/8802975" target="_self">PDF</a> </p></li>-->



<li><p><strong>Yan Huang</strong>, Qi Wu, Chunfeng Song, and Liang Wang, Learning Semantic Concepts and Order for Image and Sentence Matching, <i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, pp. 6163-6171, 2018. (<font color="#FF0000">Spotlight</font>) <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Learning_Semantic_Concepts_CVPR_2018_paper.pdf" target="_self">PDF</a> </p></li>
<li><p>Chunfeng Song, <strong>Yan Huang</strong>, Wanli Ouyang, and LiangWang, Mask-Guided Contrastive Attention Model for Person Re-Identification, <i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, pp. 1179-1188, 2018. <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Song_Mask-Guided_Contrastive_Attention_CVPR_2018_paper.pdf" target="_self">PDF</a> </p></li>
<li><p>Junbo Wang, Wei Wang, <strong>Yan Huang</strong>, Liang Wang, and Tieniu Tan, Multimodal Memory Modelling for Video Captioning, <i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, pp. 7512-7520, 2018. (<font color="#FF0000">Spotlight</font>) <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_M3_Multimodal_Memory_CVPR_2018_paper.pdf" target="_self">PDF</a> </p></li>
<li><p>Junbo Wang, Wei Wang, <strong>Yan Huang</strong>, Liang Wang, and Tieniu Tan, Hierarchical Memory Modelling for Video Captioning, <i>ACM Conference on Multimedia (<strong>MM</strong>)</i>, pp. 63-71, 2018. <a href="http://delivery.acm.org/10.1145/3250000/3240538/p63-wang.pdf?ip=159.226.178.147&id=3240538&acc=ACTIVE%20SERVICE&key=33E289E220520BFB%2E949A0B1AADF887FF%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1551078295_e37305fd2da577784915927485e580e7" target="_self">PDF</a> </p></li>
<li><p>Chenglong Li, Chengli Zhu, <strong>Yan Huang</strong>, Jin Tang, and Liang Wang, Cross-Modal Ranking with Soft Consistency and Noisy Labels for Robust RGB-T Tracking, <i>European Conference on Computer Vision (<strong>ECCV</strong>)</i>, pp. 831-847, 2018. <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Chenglong_Li_Cross-Modal_Ranking_with_ECCV_2018_paper.pdf" target="_self">PDF</a> </p></li>
<!--<li><p>Wenlong Cheng, <strong>Yan Huang</strong>, and Liang Wang, Towards Unconstrained Pointing Problem of Visual Question Answering: A Retrieval-Based Method, <strong>ICPR</strong>, 2018, accepted. (<font color="#FF0000">Oral</font>) <a href="https://ieeexplore.ieee.org/document/8546015" target="_self">PDF</a> </p></li>
<li><p>Lin Li, Zhaoxiang Zhang, <strong>Yan Huang</strong>, and Liang Wang, Deep Temporal Feature Encoding for Action Recognition, <strong>ICPR</strong>, 2018, accepted. (<font color="#FF0000">Oral</font>) <a href="https://ieeexplore.ieee.org/document/8546263" target="_self">PDF</a> </p> </li> -->

  

<li><p><strong>Yan Huang</strong>, Wei Wang, and Liang Wang, Instance-aware Image and Sentence Matching with Selective Multimodal LSTM, <i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, pp. 2310-2318, 2017. <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Instance-Aware_Image_and_CVPR_2017_paper.pdf" target="_self">PDF</a> </p></li>
<li><p>Zhen Zhou, <strong>Yan Huang</strong>, Wei Wang, Liang Wang, and Tieniu Tan, See the forest for the trees: Joint spatial and temporal recurrent neural networks for video-based person re-identification, <i>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</i>, pp. 6776-6785, 2017. <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhou_See_the_Forest_CVPR_2017_paper.pdf" target="_self">PDF</a> </p></li>
<!--<li><p>Qiyue Yin, <strong>Yan Huang</strong>, and Liang Wang, Learning Shared and Specific Factors for Multi-modal Data, <strong>CCCV</strong>, pp. 89-98, 2017. <a href="https://link.springer.com/chapter/10.1007/978-981-10-7302-1_8" target="_self">PDF</a> </p></li>-->

  
<li><p><strong>Yan Huang</strong>, Wei Wang, and Liang Wang, Bidirectional Recurrent Convolutional Networks for Multi-Frame Super-Resolution, <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, pp. 235-243, 2015. <a href="https://papers.nips.cc/paper/5778-bidirectional-recurrent-convolutional-networks-for-multi-frame-super-resolution.pdf" target="_self">PDF</a> </p></li>
<li><p><strong>Yan Huang</strong>, Wei Wang, and Liang Wang, Conditional High-order Boltzmann Machine: A Supervised Learning Model for Relation Learning, <i>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</i>, pp. 4265-4273, 2015. <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Huang_Conditional_High-Order_Boltzmann_ICCV_2015_paper.pdf" target="_self">PDF</a> </p></li>


<!--<li><p><strong>Yan Huang</strong>, Wei Wang, Liang Wang, and Tieniu Tan, A General Nonlinear Embedding Framework Based on Deep Neural Network, <strong>ICPR</strong>, pp. 732-737, 2014. (<font color="#FF0000">Oral</font>) <a href="https://ieeexplore.ieee.org/document/6976846" target="_self">PDF</a> </p></li>-->
<li><p>Peihao Huang, <strong>Yan Huang</strong>, Wei Wang, and Liang Wang, Deep Embedding Network for Clustering, <i> International Conference on Pattern Recognition (<strong>ICPR</strong>)</i>, pp. 1532-1537, 2014. (<font color="#FF0000">Best Student Paper Award</font>) <a href="https://ieeexplore.ieee.org/document/6976982" target="_self">PDF</a> </p></li>
<li><p>Wei Wang, <strong>Yan Huang</strong>, Yizhou Wang, and Liang Wang, Generalized Autoencoder: A Neural Network Framework for Dimensionality Reduction, <i>IEEE Conference on Computer Vision and Pattern Recognition Workshop (<strong>CVPRW</strong>)</i> , pp. 490-497, 2014. (<font color="#FF0000">Best Paper Award</font>) <a href="http://openaccess.thecvf.com/content_cvpr_workshops_2014/W15/papers/Wang_Generalized_Autoencoder_A_2014_CVPR_paper.pdf" target="_self">PDF</a> </p></li>
<!--<li><p><strong>Yan Huang</strong>, Wei Wang, Liang Wang, and Tieniu Tan, Multi-task Deep Neural Network for Multi-label Learning, <strong>ICIP</strong>, pp. 2897-2900, 2013. (<font color="#FF0000">Oral</font>) <a href="https://ieeexplore.ieee.org/document/6738596" target="_self">PDF</a> </p></li>
<li><p><strong>Yan Huang</strong>, Wei Wang, Liang Wang, and Tieniu Tan, An Effective Regional Saliency Model Based on Extended Site Entropy Rate, <strong>ICPR</strong>, pp. 1407-1410, 2012. <a href="https://www.computer.org/csdl/proceedings/icpr/2012/2216/00/06460404.pdf" target="_self">PDF</a> </p></li>-->

</ul>


<h2>Competitions</h2> 
<ul>
<table class="imgtable"><tr><td>
<img src="/fig/vot.png" alt="alt text" width="80" height="80" /> &nbsp;</td>
<td align="left">
<p> VOT 2019: Visual Object Tracking Challenge. Our team (Hongyuan Yu, Houwen Peng, Zhirong Wu, <b>Yan Huang</b>,
Jianlong Fu, Liang Wang) is the winner of the task: RGB-D. See details here: <a href="https://data.votchallenge.net/vot2019/presentations/vot2019_rgbd.pdf">Results of VOT 2019</a>.
</p>
</td></tr></table>

<table class="imgtable"><tr><td>
<img src="/fig/wider.png" alt="alt text" width="80" height="80" /> &nbsp;</td>
<td align="left">
<p>WIDER 2019: Wider Face and Person Challenge. Our team (Kai Niu, <b>Yan Huang</b>, Da Li, Liang Wang) is the winner of the task: PSL. See details here: <a href="https://wider-challenge.org/2019.html">Results of WIDER 2019</a>.
</p>
</td></tr></table>
</ul> 
  
  
<h2> Professional Activities</h2> 
<ul>
<li><p>Deputy Secretary General, <a href="http://ccfcv.ccf.org.cn/">China Computer Federation Technical Committee on Computer Vision</a></p></li>
<li><p>Co-Chair, <a href="https://mul-workshop.github.io/">CVPR 2020 Workshop on Multimodal Learning</a></p></li>
<li><p>Co-Chair, <a href="https://languageandvision.github.io/">CVPR 2020 Workshop on Language & Vision with Applications to Video Understanding</a></p></li>
<li><p>Co-Chair, <a href="https://cromol.github.io/">ICCV 2019 Workshop on Cross-Modal Learning in Real World</a></p></li>
<li><p>Reviewer, IEEE TPAMI, IJCV, IEEE TIP, IEEE TMM, CVPR, ICCV, ECCV, NeruIPS, AAAI, etc</p></li>
</ul>
  
  
<h2> Honors and Awards</h2> 
<ul>
<li><p>2021.01, 北京市优秀青年人才 </p> </li>
<li><p>2020.07, 北京市科技新星计划 </p> </li>
<li><p>2019.10, 微软铸星计划 </p> </li>
<li><p>2019.08, 中科院特别研究助理 </p> </li>
<li><p>2018.10, 中科院优博奖 </p> </li>
<li><p>2018.11, 中国人工智能学会优博奖 </p> </li>
<li><p>2018.06, NVIDIA Pioneering Research Award </p> </li>
<li><p>2017.06, 中科院院长特别奖</p> </li>
<li><p>2017.07, 北京市优秀毕业生</p> </li>
<li><p>2016.12, 百度奖学金</p> </li>
<li><p>2016.09, RACV Best Poster Award </p> </li>
<li><p>2015.12, 国家奖学金</p> </li>
<li><p>2014.08, ICPR Best Student Paper Award </p> </li>
<li><p>2014.06, CVPR Workshop Best Paper Award</p> </li>

</ul>


<div id="footer">
<div id="footer-text">
</br>Last updated at 2016-04-08 by Yanhua Cheng.
</div>
</div>

</div>
</body>
</html>
